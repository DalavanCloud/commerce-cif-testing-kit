##############################################################################
#
#    Copyright 2018 Adobe. All rights reserved.
#    This file is licensed to you under the Apache License, Version 2.0 (the "License");
#    you may not use this file except in compliance with the License. You may obtain a copy
#    of the License at http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software distributed under
#    the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR REPRESENTATIONS
#    OF ANY KIND, either express or implied. See the License for the specific language
#    governing permissions and limitations under the License.
#
##############################################################################

input {
    file {
        path => "/results/results.csv"
        start_position => "beginning"
        sincedb_path => "/dev/null"
    }
}

filter {
    # Parse CSV fields
    csv {
        columns => ["test_name", "status", "thread", "start_timestamp", "end_timestamp", "response_time", "data"]
        separator => ","
    }

    # Remove headline
    if [test_name] == "Name" {
        drop {}
    }

    # Convert dates
    date {
        match => ["start_timestamp" , "yyyy-MM-dd'T'HH:mm:ss.SSS", " yyyy-MM-dd'T'HH:mm:ss.SSS"]
        target => "start_timestamp"
    }

    # Convert dates
    date {
        match => ["end_timestamp" , "yyyy-MM-dd'T'HH:mm:ss.SSS", " yyyy-MM-dd'T'HH:mm:ss.SSS"]
        target => "end_timestamp"
    }

    # Add fields from JSON data field
    json {
        source => "data"
    }

    mutate {
        # Remove unused fields
        remove_field => ["path", "message", "data", "latency"]

        # Unify field naming
        rename => { "responseCode" => "response_code" }

        # Add additional data from environment
        add_field => { 
            "protocol" => "${TD_PROTOCOL}"
            "target_host" => "${TD_HOST}"
            "port" => "${TD_PORT}"
            "context_path" => "${TD_CONTEXT_PATH}"
            "mode" => "${TD_MODE}"
            "users" => "${TD_USERS}"
            "think_time" => "${TD_THINK_TIME}"
            "load_requests" => "${TD_LOAD_REQUESTS}"
            "user_id" => "${TD_USER_ID}"
            "duration" => "${TD_DURATION}"
        }
    }

    mutate {
        # Adapt data types
        convert => {
            "thread" => "integer"
            "response_time" => "integer"
            "response_code" => "integer"
            "bytes" => "integer"
            "port" => "integer"
            "users" => "integer"
            "think_time" => "integer"
            "load_requests" => "integer"
            "duration" => "integer"
            "Perf-Ow-Seq-Start-0" => "integer"
            "Perf-Ow-Seq-End-0" => "integer"
            "Perf-Backend-Req-Out-0-0" => "integer"
            "Perf-Backend-Req-Out-0-1" => "integer"
            "Perf-Backend-Req-In-0-0" => "integer"
            "Perf-Backend-Req-In-0-1" => "integer"
        }
    }

    # Remove log entries that are no requests
    if ![url] or [url] == "" {
        drop {}
    }
}

output {
    stdout {
        codec => json
        enable_metric => false
    }

    elasticsearch {
        hosts => ["elasticsearch-01", "elasticsearch-02"]
        index => "${ES_INDEX}"
        ssl => true
        user => "${ES_USERNAME}"
        password => "${ES_PASSWORD}"
        ssl_certificate_verification => false
        document_type => "toughday-request"
    }
}